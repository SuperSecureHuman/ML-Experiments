{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from adan_pytorch import Adan\n",
    "\n",
    "from utils import (resnetModel, cifar10Dataloader, train, accuracy_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/venom/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "/home/venom/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/venom/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = resnetModel(output_size=10, Pretrained=False, Device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainloader = cifar10Dataloader(num_workers=4, batch_size=32, train=True , shuffle=True, data_dir=\"./data\",pin_memory=True)\n",
    "testloader  = cifar10Dataloader(num_workers=4, batch_size=32, train=False, shuffle=True, data_dir=\"./data\",pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am using adan optimizer, instead of adam. This is because, adam optimizer, slows down when its set to captureable mode. On the other hand, adan optimizer is also promising in its resutls, and does give decent boost in performance when used in cuda graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adan(\n",
    "    model.parameters(),\n",
    "    lr=0.005,\n",
    "    betas=(0.02, 0.08, 0.01),\n",
    "    weight_decay=0.02\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 312/312 [00:06<00:00, 51.36batch/s, Accuracy=10.1]\n"
     ]
    }
   ],
   "source": [
    "accuracy_check(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1562/1562 [01:58<00:00, 13.19Batch/s, loss=1.93]\n",
      "Epoch 2: 100%|██████████| 1562/1562 [01:58<00:00, 13.23Batch/s, loss=1.41]\n",
      "Epoch 3: 100%|██████████| 1562/1562 [01:58<00:00, 13.22Batch/s, loss=1.75] \n",
      "Epoch 4: 100%|██████████| 1562/1562 [01:57<00:00, 13.25Batch/s, loss=1.18] \n",
      "Epoch 5: 100%|██████████| 1562/1562 [01:57<00:00, 13.24Batch/s, loss=1.2]  \n",
      "Test: 100%|██████████| 312/312 [00:04<00:00, 72.72batch/s, Accuracy=66.9]\n"
     ]
    }
   ],
   "source": [
    "_ = train(model, epochs=5, TrainLoader=trainloader, TestLoader=testloader, optimizer=optimizer, criterion=criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually the training loop is like this\n",
    "\n",
    "```python\n",
    "for epoch in range(1,6):\n",
    "    model.train()\n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuda graphs follows the following steps\n",
    "\n",
    "# Warmup\n",
    "\n",
    "# Record\n",
    "\n",
    "# Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_input , static_output = next(iter(trainloader))\n",
    "static_input = static_input.cuda()\n",
    "static_output = static_output.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup Time:  0.6811985969543457\n"
     ]
    }
   ],
   "source": [
    "# Warmup\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "trainStream = torch.cuda.Stream()\n",
    "trainStream.wait_stream(torch.cuda.current_stream())\n",
    "\n",
    "with torch.cuda.stream(trainStream):\n",
    "    for i in range(10):\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        output = model(static_input)\n",
    "        loss = criterion(output, static_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "torch.cuda.current_stream().wait_stream(trainStream)\n",
    "\n",
    "print(\"Warmup Time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGraph = torch.cuda.CUDAGraph()\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "with torch.cuda.graph(trainGraph):\n",
    "    output = model(static_input)\n",
    "    loss = criterion(output, static_output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1562/1562 [01:36<00:00, 16.20batch/s, Loss=0.804]\n",
      "Epoch 2: 100%|██████████| 1562/1562 [01:36<00:00, 16.23batch/s, Loss=0.655]\n",
      "Epoch 3: 100%|██████████| 1562/1562 [01:36<00:00, 16.23batch/s, Loss=0.652]\n",
      "Epoch 4: 100%|██████████| 1562/1562 [01:36<00:00, 16.25batch/s, Loss=0.703]\n",
      "Epoch 5: 100%|██████████| 1562/1562 [01:36<00:00, 16.26batch/s, Loss=0.667]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Time:  481.0689322948456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1,6):\n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(\"Epoch {}\".format(epoch))\n",
    "            static_input.copy_(data.cuda())\n",
    "            static_output.copy_(target.cuda())\n",
    "            trainGraph.replay()\n",
    "            tepoch.set_postfix(Loss=loss.item())\n",
    "\n",
    "print(\"Graph Time: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 312/312 [00:04<00:00, 70.83batch/s, Accuracy=72.3]\n"
     ]
    }
   ],
   "source": [
    "accuracy_check(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Time (no tqdm):  468.69113993644714\n"
     ]
    }
   ],
   "source": [
    "# without tqdm\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(6,11):\n",
    "    for data, target in trainloader:\n",
    "        static_input.copy_(data.cuda())\n",
    "        static_output.copy_(target.cuda())\n",
    "        trainGraph.replay()\n",
    "\n",
    "print(\"Graph Time (no tqdm): \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 312/312 [00:04<00:00, 71.33batch/s, Accuracy=75.6]\n"
     ]
    }
   ],
   "source": [
    "accuracy_check(model, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f401cf1dbab24df559ae8789ef7eacae25a0fecff741eceb08aecb7249ab0875"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
